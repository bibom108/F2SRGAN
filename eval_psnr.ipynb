{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import mobilenet_v2\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Ult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([math.exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    return window\n",
    "\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "\n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "\n",
    "def ssim(img1, img2, window_size=11, size_average=True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "\n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "    \n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
    "\n",
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, upscale_factor):\n",
    "        super(ValDataset, self).__init__()\n",
    "        # self.crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.image_filenames = [os.path.join(dataset_dir, x) for x in os.listdir(dataset_dir) if is_image_file(x)]\n",
    "        self.single_filenames = [x for x in os.listdir(dataset_dir) if is_image_file(x)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = Image.open(self.image_filenames[index]).convert('RGB')\n",
    "        image_width = (hr_image.width // self.upscale_factor) * self.upscale_factor\n",
    "        image_height = (hr_image.height // self.upscale_factor) * self.upscale_factor\n",
    "\n",
    "        hr_scale = transforms.Resize((image_height, image_width), interpolation=Image.BICUBIC)\n",
    "        lr_scale = transforms.Resize((image_height // self.upscale_factor, image_width // self.upscale_factor), interpolation=Image.BICUBIC)\n",
    "        # hr_image = transforms.CenterCrop(self.crop_size)(hr_image)\n",
    "        lr_image = lr_scale(hr_image)\n",
    "        hr_image = hr_scale(hr_image)\n",
    "        return self.single_filenames[index], to_tensor(lr_image), to_tensor(hr_image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeperableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1, bias=True):\n",
    "        super(SeperableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride = stride,\n",
    "            groups=in_channels,\n",
    "            bias=bias,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels, \n",
    "            kernel_size=1,\n",
    "            bias=bias\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "    \n",
    "\n",
    "    \n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_act=True, use_bn=True, discriminator=False, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.use_act = use_act\n",
    "        self.cnn = SeperableConv2d(in_channels, out_channels, **kwargs, bias=not use_bn)\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True) if discriminator else nn.PReLU(num_parameters=out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.cnn(x))) if self.use_act else self.bn(self.cnn(x))\n",
    "\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, scale_factor):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        \n",
    "        self.conv = SeperableConv2d(in_channels, in_channels * scale_factor**2, kernel_size=3, stride=1, padding=1)\n",
    "        self.ps = nn.PixelShuffle(scale_factor) # (in_channels * 4, H, W) -> (in_channels, H*2, W*2)\n",
    "        self.act = nn.PReLU(num_parameters=in_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.act(self.ps(self.conv(x)))\n",
    "        \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.block1 = ConvBlock(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.block2 = ConvBlock(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            use_act=False\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        return out + x\n",
    "    \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels: int = 3, num_channels: int = 64, num_blocks: int = 16, upscale_factor: int = 4):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.initial = ConvBlock(in_channels, num_channels, kernel_size=9, stride=1, padding=4, use_bn=False)\n",
    "        self.residual = nn.Sequential(\n",
    "            *[ResidualBlock(num_channels) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.convblock = ConvBlock(num_channels, num_channels, kernel_size=3, stride=1, padding=1, use_act=False)\n",
    "        self.upsampler = nn.Sequential(\n",
    "            *[UpsampleBlock(num_channels, scale_factor=2) for _ in range(upscale_factor//2)]\n",
    "        )\n",
    "        self.final_conv = SeperableConv2d(num_channels, in_channels, kernel_size=9, stride=1, padding=4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        x = self.residual(initial)\n",
    "        x = self.convblock(x) + initial\n",
    "        x = self.upsampler(x)\n",
    "        return (torch.tanh(self.final_conv(x)) + 1) / 2\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 3,\n",
    "        features: tuple = (64, 64, 128, 128, 256, 256, 512, 512),\n",
    "    ) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        blocks = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            blocks.append(\n",
    "                ConvBlock(\n",
    "                    in_channels,\n",
    "                    feature,\n",
    "                    kernel_size=3,\n",
    "                    stride=1 + idx % 2,\n",
    "                    padding=1,\n",
    "                    discriminator=True,\n",
    "                    use_act=True,\n",
    "                    use_bn=False if idx == 0 else True,\n",
    "                )\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((6, 6)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 6 * 6, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.blocks(x)\n",
    "        return torch.sigmoid(self.classifier(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "UPSCALE_FACTOR = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swiftsrgan_psnr_testing(_path, model_path, ds):\n",
    "    netG = Generator().to(DEVICE)\n",
    "    netG.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['model'])\n",
    "    netG.eval()\n",
    "    val_set = ValDataset(\n",
    "        _path, upscale_factor=UPSCALE_FACTOR\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_set, num_workers=0, batch_size=1, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, total=len(val_loader))\n",
    "\n",
    "        valing_results = {\n",
    "            \"mse\": 0,\n",
    "            \"psnr\": 0,\n",
    "            \"batch_sizes\": 0,\n",
    "            \"ssim\": 0,\n",
    "            \"ssims\": 0,\n",
    "        }\n",
    "        nums = 0\n",
    "        for name, val_lr, val_hr in val_bar:\n",
    "            batch_size = val_lr.size(0)\n",
    "            valing_results[\"batch_sizes\"] += batch_size\n",
    "            lr = val_lr\n",
    "            hr = val_hr\n",
    "            if torch.cuda.is_available():\n",
    "                lr = lr.cuda()\n",
    "                hr = hr.cuda()\n",
    "                \n",
    "            sr = netG(lr)\n",
    "\n",
    "            batch_mse = ((sr - hr) ** 2).data.mean()\n",
    "            valing_results[\"mse\"] += batch_mse * batch_size\n",
    "            batch_ssim = ssim(sr, hr).item()\n",
    "\n",
    "            valing_results[\"psnr\"] = 10 * math.log10(\n",
    "                (hr.max() ** 2)\n",
    "                / (valing_results[\"mse\"] / valing_results[\"batch_sizes\"])\n",
    "            )\n",
    "            valing_results[\"ssims\"] += batch_ssim * batch_size\n",
    "            valing_results[\"ssim\"] = (\n",
    "                valing_results[\"ssims\"] / valing_results[\"batch_sizes\"]\n",
    "            )\n",
    "            \n",
    "            torchvision.utils.save_image(\n",
    "                sr.data.cpu().squeeze(0),\n",
    "                \"./model_evaluation/data/SR/\" + ds + \"/\" + name[0]\n",
    "            )\n",
    "            nums += 1\n",
    "            # break\n",
    "    \n",
    "    return valing_results[\"psnr\"], valing_results[\"ssim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swiftsrgan_time_testing(_path, model_path, ds):\n",
    "    netG = Generator().to(DEVICE)\n",
    "    netG.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['model'])\n",
    "    netG.eval()\n",
    "    val_set = ValDataset(\n",
    "        _path, upscale_factor=UPSCALE_FACTOR\n",
    "    )\n",
    "    val_loader = DataLoader(dataset=val_set, num_workers=0, batch_size=1, shuffle=False)\n",
    "    val_bar = tqdm(val_loader, total=len(val_loader))\n",
    "\n",
    "    exec_time = 0.0\n",
    "    nums = 0\n",
    "    with torch.no_grad():\n",
    "        for name, val_lr, val_hr in val_bar:\n",
    "            lr = val_lr\n",
    "            hr = val_hr\n",
    "            if torch.cuda.is_available():\n",
    "                lr = lr.cuda()\n",
    "                hr = hr.cuda()\n",
    "\n",
    "            # torch.cuda.synchronize()\n",
    "            t0 = time.time()\n",
    "            _ = netG(lr)\n",
    "            # torch.cuda.synchronize()\n",
    "            exec_time += time.time() - t0\n",
    "            nums += 1\n",
    "    \n",
    "    return exec_time / nums\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.37it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time in Set5 = 0.32821102142333985\n",
      "PSNR in Set5 = 27.922218817626515\n",
      "SSIM in Set5 = 0.8342373847961426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:24<00:00,  1.73s/it]\n",
      "100%|██████████| 14/14 [00:10<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time in Set14 = 0.7187467302594867\n",
      "PSNR in Set14 = 24.904779334216457\n",
      "SSIM in Set14 = 0.7247450585876193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = [\"Set5\", \"Set14\"]\n",
    "model_path = \"./models/baseline.pth.tar\"\n",
    "for ds in dataset:\n",
    "    psnr, ssim_val = swiftsrgan_psnr_testing(\"./dataset/SR_testing_datasets/\" + ds, model_path, ds)\n",
    "    exec_time = swiftsrgan_time_testing(\"./dataset/SR_testing_datasets/\" + ds, model_path, ds)\n",
    "    print(f'Execution time in {ds} = {exec_time}')\n",
    "    print(f'PSNR in {ds} = {psnr}')\n",
    "    print(f'SSIM in {ds} = {ssim_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4868653bb6f8972e87e4c446ab8a445a15b25dedb8594cc74c480f8152ea86a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
