{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import mobilenet_v2\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import imageio\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Ult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([math.exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    return window\n",
    "\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "\n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "def ssim(img1, img2, window_size=11, size_average=True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "\n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "def tensors_to_imgs(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i].squeeze(0).data.cpu().numpy()\n",
    "        x[i] = x[i].clip(0, 255).round()\n",
    "        x[i] = x[i].transpose(1, 2, 0).astype(np.uint8)\n",
    "    return x\n",
    "\n",
    "def imgs_to_tensors(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i].transpose(2, 0, 1)\n",
    "        x[i] = np.expand_dims(x[i], axis=0)\n",
    "        x[i] = torch.Tensor(x[i].astype(float))\n",
    "    return x\n",
    "\n",
    "\n",
    "def rgb2y(rgb):\n",
    "    return np.dot(rgb[...,:3], [65.738/256, 129.057/256, 25.064/256]) + 16\n",
    "\n",
    "\n",
    "def compute_PSNR(out, lbl):\n",
    "    [out, lbl] = tensors_to_imgs([out, lbl])\n",
    "    out = rgb2y(out)\n",
    "    lbl = rgb2y(lbl)\n",
    "    out = out.clip(0, 255).round()\n",
    "    lbl = lbl.clip(0, 255).round()\n",
    "    diff = out - lbl\n",
    "    rmse = np.sqrt(np.mean(diff**2))\n",
    "    psnr = 20*np.log10(255/rmse)\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SeperableConv2d(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=True, padding_mode='zeros'):\n",
    "        super(SeperableConv2d, self).__init__(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=in_channels, groups=in_channels, \n",
    "                kernel_size=kernel_size, padding='same', dilation=dilation,\n",
    "                bias=bias, padding_mode=padding_mode\n",
    "            ),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        )\n",
    "\n",
    "\n",
    "class UpsampleBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, scale_factor):\n",
    "        super(UpsampleBlock, self).__init__(\n",
    "            SeperableConv2d(in_channels, in_channels * scale_factor**2, kernel_size=3),\n",
    "            nn.PixelShuffle(scale_factor),\n",
    "            nn.PReLU(num_parameters=in_channels),\n",
    "            SeperableConv2d(in_channels, in_channels * scale_factor**2, kernel_size=3),\n",
    "            nn.PixelShuffle(scale_factor),\n",
    "            nn.PReLU(num_parameters=in_channels)\n",
    "        )\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, use_bn=False, use_ffc=False, use_act=True, discriminator=False, **kwargs):\n",
    "        if use_ffc: conv = FFC(in_channels, out_channels, kernel_size=3, \n",
    "                ratio_gin=0.5, ratio_gout=0.5, inline = True\n",
    "            )\n",
    "        else: conv = SeperableConv2d(in_channels, out_channels, **kwargs)\n",
    "        m = [conv]\n",
    "        \n",
    "        if use_bn: m.append(nn.BatchNorm2d(out_channels))\n",
    "        if use_act: m.append(nn.LeakyReLU(0.2, inplace=True) if discriminator else nn.PReLU(num_parameters=out_channels))\n",
    "        super(ConvBlock, self).__init__(*m)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, index):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.block1 = ConvBlock(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            use_ffc=True if index % 2 == 0 else False\n",
    "        )\n",
    "        self.block2 = ConvBlock(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            use_act=False\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        out = out.mul(0.1)\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class MeanShift(nn.Conv2d):\n",
    "    def __init__(self, rgb_range, rgb_mean, rgb_std, sign=-1):\n",
    "        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n",
    "        std = torch.Tensor(rgb_std)\n",
    "        self.weight.data = torch.eye(3).view(3, 3, 1, 1) / std.view(3, 1, 1, 1)\n",
    "        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean) / std\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels: int = 3, num_channels: int = 64, num_blocks: int = 16, upscale_factor: int = 4):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.initial = ConvBlock(in_channels, num_channels, kernel_size=3, use_act=False)\n",
    "        self.residual = nn.Sequential(\n",
    "            *[ResidualBlock(num_channels, _) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.upsampler = UpsampleBlock(num_channels, scale_factor=2)\n",
    "        self.final_conv = SeperableConv2d(num_channels, in_channels, kernel_size=3)\n",
    "\n",
    "        rgb_mean = (0.4488, 0.4371, 0.4040)\n",
    "        rgb_std = (1.0, 1.0, 1.0)\n",
    "        rgb_range = 255\n",
    "        self.sub_mean = MeanShift(rgb_range, rgb_mean, rgb_std)\n",
    "        self.add_mean = MeanShift(rgb_range, rgb_mean, rgb_std, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.sub_mean(x)\n",
    "        initial = self.initial(x)\n",
    "        x = self.residual(initial) + initial\n",
    "        x = self.upsampler(x)\n",
    "        out = self.final_conv(x)\n",
    "        out = self.add_mean(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class FourierUnit(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, ffc3d=False, fft_norm='ortho'):\n",
    "        super(FourierUnit, self).__init__()\n",
    "        self.conv_layer = SeperableConv2d(in_channels=in_channels * 2,\n",
    "                                          out_channels=out_channels * 2,\n",
    "                                          kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "\n",
    "        self.ffc3d = ffc3d\n",
    "        self.fft_norm = fft_norm\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        r_size = x.size()\n",
    "\n",
    "        # (batch, c, h, w/2+1, 2)\n",
    "        fft_dim = (-3, -2, -1) if self.ffc3d else (-2, -1)\n",
    "        ffted = torch.fft.rfftn(x, dim=fft_dim, norm=self.fft_norm)\n",
    "        ffted = torch.stack((ffted.real, ffted.imag), dim=-1)\n",
    "        ffted = ffted.permute(0, 1, 4, 2, 3).contiguous()  # (batch, c, 2, h, w/2+1)\n",
    "        ffted = ffted.view((batch, -1,) + ffted.size()[3:])\n",
    "\n",
    "        ffted = self.conv_layer(ffted)  # (batch, c*2, h, w/2+1)\n",
    "        ffted = self.relu(ffted)\n",
    "\n",
    "        ffted = ffted.view((batch, -1, 2,) + ffted.size()[2:]).permute(\n",
    "            0, 1, 3, 4, 2).contiguous()  # (batch,c, t, h, w/2+1, 2)\n",
    "        ffted = torch.complex(ffted[..., 0], ffted[..., 1])\n",
    "\n",
    "        ifft_shape_slice = x.shape[-3:] if self.ffc3d else x.shape[-2:]\n",
    "        output = torch.fft.irfftn(ffted, s=ifft_shape_slice, dim=fft_dim, norm=self.fft_norm)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class SpectralTransform(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, enable_lfu=True, **fu_kwargs):\n",
    "        super(SpectralTransform, self).__init__()\n",
    "        self.enable_lfu = enable_lfu\n",
    "        if stride == 2:\n",
    "            self.downsample = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "        self.stride = stride\n",
    "        self.conv1 = nn.Sequential(\n",
    "            SeperableConv2d(in_channels, out_channels // 2, kernel_size=1, bias=False),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fu = FourierUnit(\n",
    "            out_channels // 2, out_channels // 2, **fu_kwargs)\n",
    "\n",
    "        if self.enable_lfu:\n",
    "            self.lfu = FourierUnit(out_channels // 2, out_channels // 2)\n",
    "        self.conv2 = SeperableConv2d(out_channels // 2, out_channels, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.downsample(x)\n",
    "        x = self.conv1(x)\n",
    "        output = self.fu(x)\n",
    "        \n",
    "        if self.enable_lfu:\n",
    "            n, c, h, w = x.shape\n",
    "            split_no = 2\n",
    "            split_h = h // split_no\n",
    "            split_w = w // split_no\n",
    "            xs = torch.cat(torch.split(x[:, :c // 4], split_h, dim=-2)[0:2], dim=1).contiguous()\n",
    "            xs = torch.cat(torch.split(xs, split_w, dim=-1)[0:2], dim=1).contiguous()\n",
    "            xs = self.lfu(xs)\n",
    "            xs = xs.repeat(1, 1, split_no, split_no).contiguous()\n",
    "\n",
    "            if h % 2 == 1:\n",
    "                h_zeros = torch.zeros(xs.shape[0], xs.shape[1], 1, xs.shape[3]).to(DEVICE)\n",
    "                xs = torch.cat((xs, h_zeros), dim=2)\n",
    "            if w % 2 == 1:\n",
    "                w_zeros = torch.zeros(xs.shape[0], xs.shape[1], xs.shape[2], 1).to(DEVICE)\n",
    "                xs = torch.cat((xs, w_zeros), dim=3)\n",
    "        else:\n",
    "            xs = 0\n",
    "\n",
    "        output = self.conv2(x + output + xs)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class FFC(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 ratio_gin, ratio_gout, inline=True, stride=1, padding=0,\n",
    "                 dilation=1, enable_lfu=True,\n",
    "                 padding_type='reflect', gated=False, **spectral_kwargs):\n",
    "        super(FFC, self).__init__()\n",
    "\n",
    "        assert stride == 1 or stride == 2, \"Stride should be 1 or 2.\"\n",
    "        self.stride = stride\n",
    "        self.inline = inline\n",
    "\n",
    "        in_cg = int(in_channels * ratio_gin)\n",
    "        in_cl = in_channels - in_cg\n",
    "        out_cg = int(out_channels * ratio_gout)\n",
    "        out_cl = out_channels - out_cg\n",
    "\n",
    "        self.ratio_gin = ratio_gin\n",
    "        self.ratio_gout = ratio_gout\n",
    "        self.global_in_num = in_cg\n",
    "\n",
    "        module = nn.Identity if in_cl == 0 or out_cl == 0 else SeperableConv2d\n",
    "        self.convl2l = module(in_cl, out_cl, kernel_size,\n",
    "                              stride, padding, dilation, padding_mode=padding_type)\n",
    "        module = nn.Identity if in_cl == 0 or out_cg == 0 else SeperableConv2d\n",
    "        self.convl2g = module(in_cl, out_cg, kernel_size,\n",
    "                              stride, padding, dilation, padding_mode=padding_type)\n",
    "        module = nn.Identity if in_cg == 0 or out_cl == 0 else SeperableConv2d\n",
    "        self.convg2l = module(in_cg, out_cl, kernel_size,\n",
    "                              stride, padding, dilation, padding_mode=padding_type)\n",
    "        module = nn.Identity if in_cg == 0 or out_cg == 0 else SpectralTransform\n",
    "        self.convg2g = module(\n",
    "            in_cg, out_cg, stride, enable_lfu, **spectral_kwargs)\n",
    "\n",
    "        self.gated = gated\n",
    "        module = nn.Identity if in_cg == 0 or out_cl == 0 or not self.gated else SeperableConv2d\n",
    "        self.gate = module(in_channels, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.inline:\n",
    "            x_l, x_g = x[:, :-self.global_in_num], x[:, -self.global_in_num:]\n",
    "        else:\n",
    "            x_l, x_g = x if type(x) is tuple else (x, 0)\n",
    "        out_xl, out_xg = 0, 0\n",
    "\n",
    "        if self.gated:\n",
    "            total_input_parts = [x_l]\n",
    "            if torch.is_tensor(x_g):\n",
    "                total_input_parts.append(x_g)\n",
    "            total_input = torch.cat(total_input_parts, dim=1)\n",
    "\n",
    "            gates = torch.sigmoid(self.gate(total_input))\n",
    "            g2l_gate, l2g_gate = gates.chunk(2, dim=1)\n",
    "        else:\n",
    "            g2l_gate, l2g_gate = 1, 1\n",
    "\n",
    "        if self.ratio_gout != 1:\n",
    "            out_xl = self.convl2l(x_l) + self.convg2l(x_g) * g2l_gate\n",
    "        if self.ratio_gout != 0:\n",
    "            out_xg = self.convl2g(x_l) * l2g_gate + self.convg2g(x_g)\n",
    "            \n",
    "        out = out_xl, out_xg\n",
    "        if self.inline:\n",
    "            out = torch.cat(out, dim=1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "UPSCALE_FACTOR = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swiftsrgan_psnr_testing(_path, model_path, ds):\n",
    "    netG = Generator().to(DEVICE)\n",
    "    netG.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['model'])\n",
    "    netG.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valing_results = {\n",
    "            \"mse\": 0,\n",
    "            \"psnr\": 0,\n",
    "            \"batch_sizes\": 0,\n",
    "            \"ssim\": 0,\n",
    "            \"ssims\": 0,\n",
    "        }\n",
    "        nums = 0\n",
    "        shutil.rmtree('./PIRM2018/your_results')\n",
    "        shutil.rmtree('./PIRM2018/self_validation_HR')\n",
    "        os.makedirs('./PIRM2018/your_results')\n",
    "        os.makedirs('./PIRM2018/self_validation_HR')\n",
    "        for name in os.listdir(_path):\n",
    "            full_path = _path + \"/\" + name\n",
    "            hr_image = Image.open(full_path).convert('RGB')\n",
    "            image_width = (hr_image.width // 4) * 4\n",
    "            image_height = (hr_image.height // 4) * 4\n",
    "            hr_scale = transforms.Resize((image_height, image_width), interpolation=Image.BICUBIC)\n",
    "            lr_scale = transforms.Resize((image_height // 4, image_width // 4), interpolation=Image.BICUBIC)\n",
    "            lr_image = lr_scale(hr_image)\n",
    "            hr_image = hr_scale(hr_image)\n",
    "            lr_image = np.asarray(lr_image)\n",
    "            hr_image = np.asarray(hr_image)\n",
    "            \n",
    "            # inp = imageio.imread(full_path)\n",
    "            # [inp] = imgs_to_tensors([inp])\n",
    "            [hr_image] = imgs_to_tensors([hr_image])\n",
    "            [lr_image] = imgs_to_tensors([lr_image])\n",
    "            out = netG(lr_image)\n",
    "\n",
    "            # valing_results[\"psnr\"] += compute_PSNR(hr_image, out)\n",
    "            # mse = ((hr_image - out) ** 2).data.mean()\n",
    "            # valing_results[\"psnr\"] += 10 * math.log10((1.0 ** 2) / (mse))\n",
    "            [out] = tensors_to_imgs([out])\n",
    "            [hr_image] = tensors_to_imgs([hr_image])\n",
    "\n",
    "            imageio.imwrite('./PIRM2018/your_results' + \"/\" + name, out)\n",
    "            imageio.imwrite(\"./PIRM2018/self_validation_HR\" + \"/\" + name, hr_image)\n",
    "            nums += 1\n",
    "    \n",
    "    return valing_results[\"psnr\"]/nums, valing_results[\"ssim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swiftsrgan_time_testing(_path, model_path, ds):\n",
    "    netG = Generator().to(DEVICE)\n",
    "    netG.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['model'])\n",
    "    netG.eval()\n",
    "\n",
    "    exec_time = 0.0\n",
    "    nums = 0\n",
    "    with torch.no_grad():\n",
    "        for name in os.listdir(_path):\n",
    "            full_path = _path + \"/\" + name\n",
    "            hr_image = Image.open(full_path).convert('RGB')\n",
    "            image_width = (hr_image.width // 4) * 4\n",
    "            image_height = (hr_image.height // 4) * 4\n",
    "            hr_scale = transforms.Resize((image_height, image_width), interpolation=Image.BICUBIC)\n",
    "            lr_scale = transforms.Resize((image_height // 4, image_width // 4), interpolation=Image.BICUBIC)\n",
    "            \n",
    "            lr_image = lr_scale(hr_image)\n",
    "            hr_image = hr_scale(hr_image)\n",
    "            lr_image = np.asarray(lr_image)\n",
    "            hr_image = np.asarray(hr_image)\n",
    "            [inp] = imgs_to_tensors([lr_image])\n",
    "            # inp = imageio.imread(full_path)\n",
    "            # [inp] = imgs_to_tensors([inp])\n",
    "\n",
    "            # torch.cuda.synchronize()\n",
    "            t0 = time.time()\n",
    "            out = netG(inp)\n",
    "            # torch.cuda.synchronize()\n",
    "            exec_time += time.time() - t0\n",
    "            nums += 1\n",
    "    \n",
    "    return exec_time / nums\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR in Set5 = 0.0\n",
      "SSIM in Set5 = 0\n"
     ]
    }
   ],
   "source": [
    "dataset = [\"Set5\"]\n",
    "model_path = \"./models/swiftfsrgan_combinev1/content/netG_4x_epoch6.pth.tar\"\n",
    "\n",
    "for ds in dataset:\n",
    "    psnr, ssim_val = swiftsrgan_psnr_testing(\"./dataset/SR_testing_datasets/\" + ds, model_path, ds)\n",
    "    # exec_time = swiftsrgan_time_testing(\"./dataset/SR_testing_datasets/\" + ds, model_path, ds)\n",
    "    # print(f'Execution time in {ds} = {exec_time}')\n",
    "    print(f'PSNR in {ds} = {psnr}')\n",
    "    print(f'SSIM in {ds} = {ssim_val}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4868653bb6f8972e87e4c446ab8a445a15b25dedb8594cc74c480f8152ea86a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
